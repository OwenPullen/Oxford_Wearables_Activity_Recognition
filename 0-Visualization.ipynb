{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# The Capture24 dataset\n",
        "\n",
        "The Capture-24 dataset consists of wrist-worn accelerometer measurements collected from about 150 participants that wore the device for 24 hours.\n",
        "\n",
        "The two main files we will work with are `X_raw.dat` and `capture24.npz`. The\n",
        "latter is a bundle of numpy arrays as shown below.\n",
        "\n",
        "We start by setting up some modules and functions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import decomposition\n",
        "from sklearn import preprocessing\n",
        "from sklearn import manifold\n",
        "import utils  # contains helper functions for this workshop -- check utils.py\n",
        "\n",
        "# For reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# A useful plotting function\n",
        "def my_scatter_plot(X, y):\n",
        "    fig, ax = plt.subplots()\n",
        "    for i in range(utils.NUM_CLASSES):\n",
        "        ax.scatter(X[y==i, 0], X[y==i, 1],\n",
        "            c=utils.COLORS[i], label=utils.CLASSES[i], alpha=0.25, s=10)\n",
        "    fig.legend()\n",
        "    return fig, ax"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Load the dataset files: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# data = np.load('capture24.npz', allow_pickle=True)\n",
        "data = np.load('capture24_small.npz', allow_pickle=True)\n",
        "print(\"Data contents:\", data.files)\n",
        "X_feats, y, pid, time, annotation = data['X_feats'], data['y'], data['pid'], data['time'], data['annotation']\n",
        "print('X_feats shape:', X_feats.shape)\n",
        "print('y shape:', y.shape)\n",
        "print('pid shape:', pid.shape)\n",
        "print('time shape:', time.shape)\n",
        "print('annotation shape:', annotation.shape)\n",
        "# X_raw = np.memmap('X_raw.dat', dtype='float32', mode='r').reshape(-1,3,3000)\n",
        "X_raw = np.load('X_raw_small.npy')\n",
        "print('X_raw shape:', X_raw.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Description of the numpy arrays*\n",
        "\n",
        "- `X_raw.dat` numpy array of shape `(N,3,3000)` where each row corresponds to 30 seconds of *raw* tri-axial acceleration measurement (at 100Hz).\n",
        "\n",
        "- `X_feats.npy` numpy array of shape `(N,125)` where each row corresponds to *hand-crafted features* for 30 seconds measurement.\n",
        "\n",
        "- `y.npy` numpy array of shape `(N,)` indicating the activity (0: sleep, 1: sedentary, 2: tasks-light, 3: walking, 4: moderate) performed during the 30 seconds measurement.\n",
        "\n",
        "- `time.npy` numpy array of shape `(N,)` indicating the start time of the corresponding measurement.\n",
        "\n",
        "- `pid.npy` numpy array of shape `(N,)` indicating the participant ID for the corresponding measurement.\n",
        "\n",
        "- `annotation.npy` numpy arrayof shape `(N,)` containing fine-grained activity annotations for the corresponding measurement.\n",
        "\n",
        "Arrays `X_feats`, `y.npy`, `time.npy`, `pid.npy` and `annotation.npy` are stored in a single `capture24.npz` file, while `X_raw.dat` is stored separately as a numpy `memmap` due to its large size (~14GB).\n",
        "\n",
        "**Note:** The provided arrays `X_feats`, `X_raw`, `y`, etc. are so that measurements of a same participant are contiguous and continuous time intervals correspond to continuous rows, however interrupts (time gaps) in the measurements may exist.\n",
        "Time discontinuities will also of course occur at the edges between participants."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualization\n",
        "Visualizing the dataset is an important part of data science. This can\n",
        "provide useful insights about the problem at hand.\n",
        "\n",
        "Let's visualize one instance of each activity type:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, axs = plt.subplots(5, sharex=True, sharey=True, figsize=(5,5))\n",
        "for i in range(utils.NUM_CLASSES):\n",
        "    axs[i].plot(X_raw[y == i][0].T)\n",
        "    axs[i].set_title(utils.CLASSES[i])\n",
        "fig.tight_layout()\n",
        "fig.show()\n",
        "# fig.savefig('activities.png', bbox_inches='tight')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After visualizing individual instances, the next step is to visualize\n",
        "our dataset as a whole to have a grasp of the data distribution. A\n",
        "standard visualization approach is to scatter-plot the two principal\n",
        "components of our dataset.\n",
        "For performance, in the following we perform visualizations on\n",
        "smaller subsets of our data since our data is rather big:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# grab first 10k\n",
        "X_raw = X_raw[:10000]\n",
        "X_feats = X_feats[:10000]\n",
        "y = y[:10000]\n",
        "pid = pid[:10000]\n",
        "time = time[:10000]\n",
        "annotation = annotation[:10000]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Perform PCA on our raw dataset: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Plotting first two PCA components...\")\n",
        "scaler = preprocessing.StandardScaler()  # PCA requires normalized data\n",
        "X_raw_scaled = scaler.fit_transform(X_raw.reshape(X_raw.shape[0],-1))\n",
        "pca = decomposition.PCA(n_components=2)  # two components\n",
        "X_pca = pca.fit_transform(X_raw_scaled)\n",
        "fig, ax = my_scatter_plot(X_pca, y)\n",
        "fig.show()\n",
        "# fig.savefig('pca_plot.png', bbox_inches='tight')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The PCA plot is already very informative. What if we want to\n",
        "visualize more components? A popular high-dimensional data visualization tool\n",
        "is _t-distributed stochastic neighbor embedding_ (t-SNE). We next use t-SNE to\n",
        "visualize 128 principal components of our raw dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Plotting t-SNE on PCA components...\")\n",
        "pca = decomposition.PCA(n_components=128)  # 128 components\n",
        "X_pca = pca.fit_transform(X_raw_scaled)\n",
        "tsne = manifold.TSNE(n_components=2,  # project down to 2 components\n",
        "    init='random', random_state=42, perplexity=100)\n",
        "X_tsne_pca = tsne.fit_transform(X_pca)\n",
        "fig, ax = my_scatter_plot(X_tsne_pca, y)\n",
        "fig.show()\n",
        "# fig.savefig('tsne_on_pca_plot.png', bbox_inches='tight')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, let's perform a t-SNE visualization this time on the\n",
        "hand-crafted features `X_feats`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Plotting t-SNE on hand-crafted features...\")\n",
        "tsne = manifold.TSNE(n_components=2,\n",
        "    init='random', random_state=42, perplexity=100)\n",
        "X_tsne_feats = tsne.fit_transform(X_feats)\n",
        "fig, ax = my_scatter_plot(X_tsne_feats, y)\n",
        "fig.show()\n",
        "# fig.savefig('tsne_on_feats_plot.png', bbox_inches='tight')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our preliminary plots seem to suggest that classifying \"sleep\" and\n",
        "\"sedentary\" activities may be easy while classifying \"tasks-light\", \"walking\"\n",
        "and \"moderate\" activities may be more challenging.\n",
        "\n",
        "*To try:*\n",
        "\n",
        "- Tune the `perplexity` parameter of t-SNE to see how it affects the plots.\n",
        "- Our dataset is highly unbalanced:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(np.unique(y, return_counts=True))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As seen, there is barely any \"tasks-light\" activities (category 2). To aid the\n",
        "visualization, try balancing the activities to be scatter-plotted."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}