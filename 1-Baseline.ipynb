{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity recognition on the Capture24 dataset\n",
    "\n",
    "Our aim is to build a baseline machine learning model to recognize\n",
    "activities from wrist-worn accelerometer measurements.\n",
    "Our baseline is a random forest classifier trained on the hand-crafted\n",
    "features `X_feats`.\n",
    "\n",
    "Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import utils  # contains helper functions for this workshop -- check utils.py\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# A useful plotting function\n",
    "def plot_activity(X, y, pid, time, ipid=3):\n",
    "    mask = pid == ipid\n",
    "    return utils.plot_activity(X[:,0][mask], y[mask], time[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Load dataset and hold out some instances for testing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# data = np.load('capture24.npz', allow_pickle=True)\n",
    "data = np.load('capture24_small.npz', allow_pickle=True)\n",
    "print(\"Data contents:\", data.files)\n",
    "X, y, pid, time = data['X_feats'], data['y'], data['pid'], data['time']\n",
    "\n",
    "# Hold out some participants for testing the model\n",
    "test_pids = [2, 3]\n",
    "test_mask = np.isin(pid, test_pids)\n",
    "train_mask = ~np.isin(pid, test_pids)\n",
    "X_train, y_train, pid_train, time_train = X[train_mask], y[train_mask], pid[train_mask], time[train_mask]\n",
    "X_test, y_test, pid_test, time_test = X[test_mask], y[test_mask], pid[test_mask], time[test_mask]\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Train a random forest classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argument oob_score=True to be used for HMM smoothing (see below)\n",
    "classifier = RandomForestClassifier(n_estimators=100, oob_score=True, n_jobs=2)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = classifier.predict(X_test)\n",
    "print(\"\\n--- Random forest performance ---\")\n",
    "print(\"Cohen kappa score:\", utils.cohen_kappa_score(y_test, y_test_pred, pid_test))\n",
    "print(\"Accuracy score:\", utils.accuracy_score(y_test, y_test_pred, pid_test))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Plot activity timeseries for participant #3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_activity(X_test, y_test_pred, pid_test, time_test, ipid=3)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest classifier performs descently well.\n",
    "However, the model does not account for temporal dependencies since we simply\n",
    "trained it to classify individual intervals of 30 seconds of activity.\n",
    "This can be seen in the activity plot where the sleep period is not smooth.\n",
    "To account for the temporal component, we consider smoothing the predictions\n",
    "by applying a mode filter, i.e. we pass a window (here of size 3) along the\n",
    "timeseries and pick the most popular activity within the window.\n",
    "\n",
    "**Note:** As mentioned before, the provided arrays `X_feats`, `X_raw`, `y`, etc. are so that measurements of a same participant are contiguous and continuous time intervals correspond to continuous rows, however interrupts (time gaps) in the measurements may exist.\n",
    "Time discontinuities will also of course occur at the edges between participants.\n",
    "In the following time smoothing approaches we do not account for these interrupts -- the number of these are negligible so we ignore them. You could properly account for them by looking at the `time` and `pid` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_modefilt = mode(\n",
    "    np.vstack((y_test_pred[:-2], y_test_pred[1:-1], y_test_pred[2:])),\n",
    "    axis=0)[0].ravel()\n",
    "y_test_modefilt = np.concatenate(([y_test_pred[0]], y_test_modefilt, [y_test_pred[-1]]))\n",
    "print(\"\\n--- Random forest performance with mode filtering ---\")\n",
    "print(\"Cohen kappa score:\", utils.cohen_kappa_score(y_test, y_test_modefilt, pid_test))\n",
    "print(\"Accuracy score:\", utils.accuracy_score(y_test, y_test_modefilt, pid_test))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_test_modefilt))\n",
    "\n",
    "fig, ax = plot_activity(X_test, y_test_modefilt, pid_test, time_test, ipid=3)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this simple mode smoothing improves both accuracy and kappa\n",
    "scores, and the activity plot is now smoother.\n",
    "\n",
    "A more principled approch is to use a Hidden Markov Model (HMM). Here we\n",
    "assume that the random forest predictions are mere \"observations\" of the\n",
    "\"hidden ground truth\".\n",
    "HMM requires that we obtain prior, emission and transition matrices. We can\n",
    "estimate these using the ground truth labels `y_train` together with the\n",
    "classifier's probabilistic predictions on the training set (`predict_proba` method on `X_train`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = classifier.predict_proba(X_train)\n",
    "prior, emission, transition = utils.train_hmm(Y_train_pred, y_train)\n",
    "y_test_hmm_in = utils.viterbi(y_test_pred, prior, transition, emission)\n",
    "print(\"\\n--- Random forest performance with HMM smoothing (in-bag estimate) ---\")\n",
    "print(\"Cohen kappa score:\", utils.cohen_kappa_score(y_test, y_test_hmm_in, pid_test))\n",
    "print(\"Accuracy score:\", utils.accuracy_score(y_test, y_test_hmm_in, pid_test))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_test_hmm_in))\n",
    "\n",
    "fig, ax = plot_activity(X_test, y_test_hmm_in, pid_test, time_test, ipid=3)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HMM smoothing further improves the scores, and the activity plot is even smoother.\n",
    "\n",
    "The random forest classifier can provide out-of-bag estimates on the training set (enabled by passing the `oob_score=True` argument), accessible via the attribute `oob_decision_function_`. These estimated predictions are closer to the actual out-of-sample performance of the model. We can use these to compute again the HMM parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_oob = classifier.oob_decision_function_\n",
    "prior, emission, transition = utils.train_hmm(Y_oob, y_train)\n",
    "y_test_hmm_out = utils.viterbi(y_test_pred, prior, transition, emission)\n",
    "print(\"\\n--- Random forest performance with HMM smoothing (out-of-bag estimate) ---\")\n",
    "print(\"Cohen kappa score:\", utils.cohen_kappa_score(y_test, y_test_hmm_out, pid_test))\n",
    "print(\"Accuracy score:\", utils.accuracy_score(y_test, y_test_hmm_out, pid_test))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_test_hmm_out))\n",
    "\n",
    "fig, ax = plot_activity(X_test, y_test_hmm_in, pid_test, time_test, ipid=3)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Is a simple logistic regression enough?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_LR = LogisticRegression(\n",
    "    random_state=42, solver='saga', multi_class='multinomial', max_iter=10000, n_jobs=2)\n",
    "classifier_LR.fit(X_train, y_train)\n",
    "y_test_LR = classifier_LR.predict(X_test)\n",
    "print(\"\\n--- Logistic regression performance ---\")\n",
    "print(\"Cohen kappa score:\", utils.cohen_kappa_score(y_test, y_test_LR, pid_test))\n",
    "print(\"Accuracy score:\", utils.accuracy_score(y_test, y_test_LR, pid_test))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_test_LR))\n",
    "\n",
    "fig, ax = plot_activity(X_test, y_test_LR, pid_test, time_test, ipid=3)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we apply HMM smoothing on the logistic regression predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_LR_pred = classifier_LR.predict_proba(X_train)\n",
    "prior, emission, transition = utils.train_hmm(Y_train_LR_pred, y_train)\n",
    "y_test_LR_hmm = utils.viterbi(y_test_LR, prior, transition, emission)\n",
    "print(\"\\n--- Logistic regression performance with HMM smoothing ---\")\n",
    "print(\"Cohen kappa score:\", utils.cohen_kappa_score(y_test, y_test_LR_hmm, pid_test))\n",
    "print(\"Accuracy score:\", utils.accuracy_score(y_test, y_test_LR_hmm, pid_test))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_test_LR_hmm))\n",
    "\n",
    "fig, ax = plot_activity(X_test, y_test_LR_hmm, pid_test, time_test, ipid=3)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HMM on top of the logistic regression model substantially improves its\n",
    "performance. But although the predictions are smooth, the scores are much\n",
    "lower than in the previous models.\n",
    "\n",
    "Now that we have repeatedly evaluated on the test set and taken decisions\n",
    "based on it (we have abused the test set), the reported scores are no longer\n",
    "an unbiased estimate of the generalization performance. Our test set has\n",
    "become a \"validation set\" (link). A true test set will be provided at the end\n",
    "of this workshop to truly assess the performance of your model.\n",
    "\n",
    "*To try:*\n",
    "\n",
    "- Tune hyperparameters of the random forest (`n_estimators`, `max_depth`,\n",
    "`criterion`, etc.). See [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
    "- Tune the hyperparameters of the logistic regression (`penalty`, `C`, `max_iter`, etc.). See [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "- How would you select the best set of hyperparameters for a model?\n",
    "- Can we improve performance by balancing the dataset?\n",
    "- Given that the dataset is highly unbalanced, should we focus solely on the accuracy score?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
